<!doctype html><html><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>OpenMP and rand() function - A small story - Mahesh's Blog</title><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="I have a parallel programming subject this semester, and as usual, there&rsquo;s also a lab in which we try and execute small programs. Mostly OpenMP programs.
First program is to find the value of Pi using Monte carlo methods. We have to then measure the performance with different number of threads, and tabulate it.
Usually, when we add threads using pragma omp parallel for directive, we expect the program to take less time."><meta property="og:image" content><meta property="og:title" content="OpenMP and rand() function - A small story"><meta property="og:description" content="I have a parallel programming subject this semester, and as usual, there&rsquo;s also a lab in which we try and execute small programs. Mostly OpenMP programs.
First program is to find the value of Pi using Monte carlo methods. We have to then measure the performance with different number of threads, and tabulate it.
Usually, when we add threads using pragma omp parallel for directive, we expect the program to take less time."><meta property="og:type" content="article"><meta property="og:url" content="https://mahesh-hegde.github.io/posts/omp_rand_critical_section/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-07T18:35:13+05:30"><meta property="article:modified_time" content="2023-01-07T18:35:13+05:30"><meta name=twitter:card content="summary"><meta name=twitter:title content="OpenMP and rand() function - A small story"><meta name=twitter:description content="I have a parallel programming subject this semester, and as usual, there&rsquo;s also a lab in which we try and execute small programs. Mostly OpenMP programs.
First program is to find the value of Pi using Monte carlo methods. We have to then measure the performance with different number of threads, and tabulate it.
Usually, when we add threads using pragma omp parallel for directive, we expect the program to take less time."><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script>
<link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@1,500&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css2?family=Fira+Sans&display=swap" rel=stylesheet><link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel=stylesheet><link rel=stylesheet type=text/css media=screen href=https://mahesh-hegde.github.io/css/main.ac08a4c9714baa859217f92f051deb58df2938ec352b506df655005dcaf98cc0.css><link id=darkModeStyle rel=stylesheet type=text/css href=https://mahesh-hegde.github.io/css/dark.726cd11ca6eb7c4f7d48eb420354f814e5c1b94281aaf8fd0511c1319f7f78a4.css disabled></head><body><div class=content><header><div class=main><a href=https://mahesh-hegde.github.io/>Mahesh's Blog</a></div><nav><a href=/>Home</a>
<a href=/posts>All posts</a>
<a href=/about>About</a>
<a href=/tags>Tags</a>
| <a id=dark-mode-toggle onclick=toggleTheme() href></a>
<script src=https://mahesh-hegde.github.io/js/themetoggle.js></script></nav></header><main><article><div class=title><h1 class=title>OpenMP and rand() function - A small story</h1><div class=meta>Posted on Jan 7, 2023</div></div><section class=body><p>I have a parallel programming subject this semester, and as usual, there&rsquo;s also a lab in which we try and execute small programs. Mostly OpenMP programs.</p><p>First program is to find the value of <code>Pi</code> using Monte carlo methods. We have to then measure the performance with different number of threads, and tabulate it.</p><p>Usually, when we add threads using <code>pragma omp parallel for</code> directive, we expect the program to take less time. Here&rsquo;s an implementation that everyone wrote:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#75715e>#pragma omp parallel for
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> nIter; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>	x <span style=color:#f92672>=</span> (<span style=color:#66d9ef>double</span>)<span style=color:#a6e22e>rand</span>() <span style=color:#f92672>/</span> RAND_MAX;
</span></span><span style=display:flex><span>	y <span style=color:#f92672>=</span> (<span style=color:#66d9ef>double</span>)<span style=color:#a6e22e>rand</span>() <span style=color:#f92672>/</span> RAND_MAX;
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>if</span> ((x<span style=color:#f92672>*</span>x <span style=color:#f92672>+</span> y<span style=color:#f92672>*</span>y) <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>1</span>) count<span style=color:#f92672>++</span>;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#66d9ef>return</span> <span style=color:#ae81ff>4</span> <span style=color:#f92672>*</span> (<span style=color:#66d9ef>double</span>)count<span style=color:#f92672>/</span>nIter;
</span></span></code></pre></div><p>But surprisingly, this doesn&rsquo;t give the results you would expect. In fact, the run time strictly increases with number of threads.</p><p><img src=/images/omp_rand_critical_section/Screenshot_Before.png alt="Counter-intuitive results with naive openmp pragma"></p><p>I was surprised, but seeing that everyone got the same results, I too first ignored the problem. But it was kind of a surprising result.</p><p>However, later I realized the problem. <code>rand()</code> is called from all threads. Each subsequent output of <code>rand()</code> is different so apparently it stores some global state. And usually that means locking.</p><p>Turns out my suspicion was true. I looked around in the <a href="https://sourceware.org/git/?p=glibc.git&a=search&h=HEAD&st=grep&s=rand%28%29">glibc sources</a>. There&rsquo;s a locking call in <a href="https://sourceware.org/git/?p=glibc.git;a=blob;f=stdlib/random.c;hb=ae612c45efb5e34713859a5facf92368307efb6e">random.c</a> and this comment confirms it.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>194 /* POSIX.1c requires that there is mutual exclusion for the `rand&#39; and
</span></span><span style=display:flex><span>195    `srand&#39; functions to prevent concurrent calls from modifying common
</span></span><span style=display:flex><span>196    data.  */
</span></span></code></pre></div><p>So rand() is obtaining a mutex, which is negating any benefit we get from OpenMP pragmas.</p><p>Solution? This is what I arrived at with some fiddling. Basically using a local, reentrant version of <code>rand</code> - called <code>rand_r</code> and using a private variable to store the random state.</p><p>By doing this, each thread has a local state for random number generation. Thus locking will not be needed.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-c data-lang=c><span style=display:flex><span><span style=color:#75715e>#pragma omp parallel
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>{
</span></span><span style=display:flex><span><span style=color:#66d9ef>int</span> localCount <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span><span style=color:#75715e>// This is the seed value for rand_r function.
</span></span></span><span style=display:flex><span><span style=color:#75715e>// (should actually use something better here than clock)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>unsigned</span> <span style=color:#66d9ef>int</span> randomState <span style=color:#f92672>=</span> <span style=color:#a6e22e>clock</span>();
</span></span><span style=display:flex><span><span style=color:#75715e>#pragma omp for
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#66d9ef>for</span> (<span style=color:#66d9ef>int</span> i <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>; i <span style=color:#f92672>&lt;</span> nIter; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>	x <span style=color:#f92672>=</span> (<span style=color:#66d9ef>double</span>)<span style=color:#a6e22e>rand_r</span>(<span style=color:#f92672>&amp;</span>randomState) <span style=color:#f92672>/</span> RAND_MAX;
</span></span><span style=display:flex><span>	y <span style=color:#f92672>=</span> (<span style=color:#66d9ef>double</span>)<span style=color:#a6e22e>rand_r</span>(<span style=color:#f92672>&amp;</span>randomState) <span style=color:#f92672>/</span> RAND_MAX;
</span></span><span style=display:flex><span>	<span style=color:#66d9ef>if</span> ((x<span style=color:#f92672>*</span>x <span style=color:#f92672>+</span> y<span style=color:#f92672>*</span>y) <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>1</span>) localCount<span style=color:#f92672>++</span>;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#75715e>#pragma omp critical
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>count <span style=color:#f92672>+=</span> localCount;
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span><span style=color:#66d9ef>return</span> <span style=color:#ae81ff>4</span> <span style=color:#f92672>*</span> (<span style=color:#66d9ef>double</span>)count<span style=color:#f92672>/</span>nIter;
</span></span></code></pre></div><p>This fixes the speed problem. But there&rsquo;s still a limit to parallelism depending on your machine&rsquo;s specs, and there may be further bottlenecks in the program as well.</p><p>But for the purpose of the lab, I get a decent graph which shows an increase in speed :P.</p><p><img src=/images/omp_rand_critical_section/Screenshot_After.png alt="After eliminating critical section"></p></section><div class=post-tags><nav class="nav tags"><ul class=tags><li><a href=/tags/c>c</a></li><li><a href=/tags/performance>performance</a></li></ul></nav></div></article></main><footer><div style=display:flex><a class=soc href=https://github.com/mahesh-hegde title=GitHub><i data-feather=github></i></a>
<a class=border></a><a class=soc href=https://twitter.com/never_inline/ title=Twitter><i data-feather=twitter></i></a>
<a class=border></a><a class=soc href=https://www.linkedin.com/in/mahesh-bhaskar-hegde title=LinkedIn><i data-feather=linkedin></i></a>
<a class=border></a></div><div class=footer-info>2023 <a href=https://github.com/athul/archie>Archie Theme</a> | Built with <a href=https://gohugo.io>Hugo</a></div></footer><script>feather.replace()</script></div></body></html>